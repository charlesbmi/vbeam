{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Play With the Speed of Sound\n",
    "We're using the `PICMUS_carotid_cross.uff` dataset, which requires a good amount of computations. We should expect things to use a lot of memory and to run a bit slower than if using scan line imaging datasets.\n",
    "\n",
    "We're using `\"JAX\"` as the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from pyuff_ustb import Uff\n",
    "\n",
    "from vbeam.beamformers import get_beamformer\n",
    "from vbeam.data_importers import import_pyuff\n",
    "from vbeam.fastmath import backend_manager\n",
    "from vbeam.util.download import cached_download\n",
    "\n",
    "backend_manager.active_backend = \"jax\"\n",
    "\n",
    "data_url = \"http://www.ustb.no/datasets/PICMUS_carotid_cross.uff\"\n",
    "uff = Uff(cached_download(data_url))\n",
    "channel_data = uff.read(\"/channel_data\")\n",
    "scan = uff.read(\"/scan\")\n",
    "\n",
    "imported_data = import_pyuff(channel_data, scan, frames=0)\n",
    "jitted_beamformer = jax.jit(get_beamformer(imported_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Big is this Dataset?\n",
    "`PICMUS_carotid_cross.uff` is pretty large. The image size is 387x609. Each pixel is imaged by each of the 128 receivers before being combined into an image. There are 75 transmits, aka images. There is however, only one frame\n",
    "\n",
    "`387*609*128*75 = 2.26E+09` pixel calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_size = imported_data.scan.x.size\n",
    "z_axis_size = imported_data.scan.z.size\n",
    "num_frames = imported_data.signal.shape[0]\n",
    "num_transmits = imported_data.signal.shape[1]\n",
    "num_receivers = imported_data.signal.shape[2]\n",
    "print((num_frames, num_transmits, num_receivers, x_axis_size, z_axis_size))\n",
    "print(f\"{num_frames*num_transmits*num_receivers*x_axis_size * z_axis_size:.2E} pixel calculations\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Speed of Sound Samples\n",
    "Let's generate random 20x20 speed of sound samples between 500 and 2000, beamform using that speed of sound, and save the result. Let's do it 10 times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from vbeam.speed_of_sound import HeterogeneousSpeedOfSound\n",
    "from vbeam.interpolation import FastInterpLinspace\n",
    "import time\n",
    "\n",
    "min_x, max_x, min_z, max_z = (\n",
    "    imported_data.scan.x[0],\n",
    "    imported_data.scan.x[-1],\n",
    "    imported_data.scan.z[0],\n",
    "    imported_data.scan.z[-1],\n",
    ")\n",
    "\n",
    "size = 20\n",
    "x_axis = FastInterpLinspace(min_x, (max_x - min_x) / size, size)\n",
    "z_axis = FastInterpLinspace(min_z, (max_z - min_z) / size, size)\n",
    "n_samples = int(np.sqrt(2 * size**2))\n",
    "\n",
    "result_samples = []\n",
    "total_time_beamforming = 0\n",
    "for i in range(10):\n",
    "    sos_values = np.random.uniform(1400, 1700, (size, size))\n",
    "    sos = HeterogeneousSpeedOfSound(sos_values, x_axis, z_axis, n_samples)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    result = jitted_beamformer(speed_of_sound=sos).block_until_ready()\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "    total_time_beamforming += elapsed_time\n",
    "\n",
    "    result_samples.append((result, sos_values))\n",
    "\n",
    "f\"{total_time_beamforming*100:.2f} milliseconds on average (including compilation)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result, sos_values = result_samples[0]\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "fig.suptitle(\"What's wrong, doctor?\")\n",
    "sos_im = ax[0].imshow(sos_values.T, aspect=\"auto\")\n",
    "ax[0].set_title(\"Speed of sound\")\n",
    "beamformed_im = ax[1].imshow(result.T, aspect=\"auto\")\n",
    "ax[1].set_title(\"Beamformed image\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Results\n",
    "Let's plot the results and save them as a GIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "\n",
    "def make_animation(result_samples):\n",
    "    result, sos_values = result_samples[0]\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2)\n",
    "    fig.suptitle(\"What's wrong, doctor?\")\n",
    "    sos_im = ax[0].imshow(sos_values.T, aspect=\"auto\")\n",
    "    ax[0].set_title(\"Speed of sound\")\n",
    "    beamformed_im = ax[1].imshow(result.T, aspect=\"auto\")\n",
    "    ax[1].set_title(\"Beamformed image\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    def animate(i):\n",
    "        result, sos_values = result_samples[i]\n",
    "        beamformed_im.set_array(result.T)\n",
    "        sos_im.set_array(sos_values.T)\n",
    "        return (beamformed_im, sos_im)\n",
    "\n",
    "    # call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "    return FuncAnimation(fig, animate, frames=len(result_samples) - 1, blit=True)\n",
    "\n",
    "\n",
    "make_animation(result_samples).save(\"temp.gif\", writer=PillowWriter(fps=6))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waving With the Waves\n",
    "Here's a bonus animation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_samples = []\n",
    "for phase in np.linspace(0, np.pi * 2, 20):\n",
    "    sos_values = (np.sin(np.arange(size) / size * np.pi - phase) + 2) * 1000\n",
    "    sos_values = np.tile(sos_values, (size, 1)).T\n",
    "    sos = HeterogeneousSpeedOfSound(sos_values, x_axis, z_axis, n_samples)\n",
    "    result_samples.append((jitted_beamformer(speed_of_sound=sos), sos_values))\n",
    "\n",
    "make_animation(result_samples).save(\"temp2.gif\", writer=PillowWriter(fps=12))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vbeam_magnusk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c4250dae465aee4b6d69a64fe17fd966e6e25e24e55c1bfcae3c87f6496b0f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
